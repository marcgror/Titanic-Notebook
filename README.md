# Titanic-Notebook
The Jupyter notebook I used in the famous Kaggle Competition Titanic: Machine Learning from Disaster. I obtained a score of 0.79 with the best model. It is not an awesome score, but the task allowed me to enter in the Machine Learning world with real data, and thus managing a project by me own.

The notebook consists in the following:
  - cleaning and preparing the data ( null values, useless columns, feauture engineering...)
  - Exploratory Data Analysis
  - Machine Learning Models: prepare the data and train a few models with default hyperparameters.
  - implementing Cross-Validation
  - Hyperparameter tuning: for the best performance models, use Grid Search to optimize hyperparameters
  - Ensemble Learning: stack the tuned models to build an even better model.
  
As I said in the introduction, my goal was not to get an incredible score, but get in touch with the main and basic ML algorithms, and more advanced topics as hyperparamter tuning or Ensemble Learning, while understanding the importance of doing a previous EDA for knowing your dataset and its trens.
